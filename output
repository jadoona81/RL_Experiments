areaDimLimit: 12.0
side:4
9
12.0
0 0
0 1
0 2
1 0
1 1
1 2
2 0
2 1
2 2
[(0, 0), (0, 4), (0, 8), (4, 0), (4, 4), (4, 8), (8, 0), (8, 4), (8, 8)]
{(0, 0): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E6AC70>, (0, 4): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E6AD90>, (0, 8): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E6AEB0>, (4, 0): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E6AFD0>, (4, 4): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E87130>, (4, 8): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E87250>, (8, 0): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E87370>, (8, 4): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E87490>, (8, 8): <OneDroneMobileTargetsEnv.OneDroneMobileTargetsEnv.state object at 0x0000021616E875B0>}
0 0
0 1
0 2
1 0
created target 0loc 7.435870295483085, 0.2654930686637851
cell 4, 0: 1
0 0
created target 1loc 0.8003793425248573, 2.7495488358273916
cell 0, 0: 1
[<mobileTarget.mobileTarget object at 0x0000021616E87700>, <mobileTarget.mobileTarget object at 0x0000021616E87AC0>]
Discrete(9)
9
resetting=============
selected start location: 0, 0
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
2--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 135.13910524340096
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 147.0782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 156.6782104868019
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 208.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 218.2782104868019
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 227.8782104868019
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 301.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 353.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 426.9564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 500.4955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 510.0955262170048
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 519.6955262170048
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 593.2346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 645.2346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 654.8346314604058
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
15--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 728.3737367038068
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 52.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 104.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 113.6
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 123.19999999999999
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 132.79999999999998
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 142.39999999999998
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 194.39999999999998
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 203.99999999999997
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 255.99999999999997
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 329.5391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
10--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 381.5391052434009
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 121.53910524340097
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 195.07821048680194
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 204.67821048680193
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 214.27821048680192
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 223.87821048680192
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 233.4782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 307.0173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 359.0173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 368.6173157302029
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 420.6173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 494.1564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 503.7564209736039
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 513.3564209736039
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 565.3564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 617.3564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 669.3564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 678.9564209736039
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 752.4955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 762.0955262170049
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 814.0955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 823.695526217005
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 833.295526217005
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 842.895526217005
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 852.495526217005
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 862.095526217005
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 871.6955262170051
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 881.2955262170051
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 890.8955262170051
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 942.8955262170051
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 994.8955262170051
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1004.4955262170051
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1078.034631460406
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1151.5737367038068
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
38--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 1203.5737367038068
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 61.6
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 71.2
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 80.80000000000001
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 90.4
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 142.4
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 215.93910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
7--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 267.93910524340095
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 147.0782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
2--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 199.0782104868019
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 80.80000000000001
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 90.4
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 100.0
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 109.6
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 161.6
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
8--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 213.6
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
1--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 61.6
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 57.60000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 67.20000000000002
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 119.20000000000002
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 128.8
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
9--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 202.33910524340098
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 80.80000000000001
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 90.4
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
5--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 163.93910524340095
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
5--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 100.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
1--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 125.53910524340095
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 57.60000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 67.20000000000002
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 76.80000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 86.4
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 96.0
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 105.6
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 115.19999999999999
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 124.79999999999998
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 134.39999999999998
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 143.99999999999997
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 153.59999999999997
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 163.19999999999996
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
17--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 215.19999999999996
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
2--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 71.2
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 121.53910524340097
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 131.13910524340096
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 140.73910524340096
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 214.27821048680192
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 287.8173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 361.35642097360386
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 370.9564209736039
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 380.5564209736039
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 390.15642097360393
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 399.75642097360395
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 409.356420973604
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 482.89552621700494
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 534.895526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 544.495526217005
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 596.495526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 648.495526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 722.034631460406
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 774.034631460406
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 783.634631460406
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 857.173736703807
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 930.712841947208
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 940.312841947208
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 949.912841947208
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 959.512841947208
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 969.112841947208
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 978.7128419472081
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1052.251947190609
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
32--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 1104.251947190609
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 125.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 135.13910524340096
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 144.73910524340096
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 154.33910524340095
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 163.93910524340095
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 173.53910524340094
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 183.13910524340093
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 235.13910524340093
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 244.73910524340093
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 254.33910524340092
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 306.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 379.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 453.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 505.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 578.9564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 652.4955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 726.0346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 778.0346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 830.0346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 839.6346314604058
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 891.6346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 901.2346314604058
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 953.2346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1026.7737367038067
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1100.3128419472075
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1152.3128419472075
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1161.9128419472074
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1235.4519471906083
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1245.0519471906082
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1254.651947190608
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1328.191052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1380.191052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1432.191052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1505.7301576774098
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1557.7301576774098
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1631.2692629208107
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1704.8083681642115
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1778.3474734076124
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1787.9474734076123
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1797.5474734076122
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1807.147473407612
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1816.747473407612
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1826.347473407612
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1835.9474734076118
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1845.5474734076117
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1855.1474734076116
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1864.7474734076116
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1874.3474734076115
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1947.8865786510123
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 2021.4256838944132
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 2073.425683894413
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
52--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 2146.964789137814
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 135.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 144.73910524340096
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 196.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 270.2782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 343.8173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 353.4173157302029
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 426.9564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 436.5564209736039
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 510.0955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 562.0955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
12--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 635.6346314604058
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 52.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 104.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 113.6
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 123.19999999999999
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 132.79999999999998
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 142.39999999999998
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 151.99999999999997
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 161.59999999999997
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 235.13910524340093
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 287.13910524340093
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 296.73910524340096
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 306.339105243401
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 315.939105243401
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 367.939105243401
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 419.939105243401
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 429.539105243401
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 439.13910524340105
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 491.13910524340105
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 500.73910524340107
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 510.3391052434011
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 519.9391052434011
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 593.478210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 667.017315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 676.617315730203
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 728.617315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 780.617315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 832.617315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 842.217315730203
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 851.8173157302031
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 903.8173157302031
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 977.356420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 986.956420973604
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 996.5564209736041
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1048.556420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1100.556420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1110.1564209736039
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1119.7564209736038
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1171.7564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1223.7564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1233.3564209736037
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1242.9564209736036
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1252.5564209736035
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1262.1564209736034
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1271.7564209736033
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1281.3564209736032
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1290.9564209736031
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1300.556420973603
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1310.156420973603
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1319.7564209736029
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1329.3564209736028
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1338.9564209736027
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1348.5564209736026
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1358.1564209736025
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1367.7564209736024
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1377.3564209736023
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1386.9564209736022
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1460.495526217003
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
57--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 1512.495526217003
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 71.2
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 144.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 196.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 270.2782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 322.2782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 331.87821048680195
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 405.4173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
9--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 478.9564209736039
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 57.60000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
6--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 109.60000000000001
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 92.73910524340096
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 166.27821048680192
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 175.87821048680192
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 185.4782104868019
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 237.4782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
7--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 311.0173157302029
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 125.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 199.0782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 251.0782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 260.6782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 334.21731573020287
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 407.75642097360384
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 417.35642097360386
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 426.9564209736039
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 436.5564209736039
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 446.15642097360393
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 455.75642097360395
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 529.2955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 602.8346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 612.4346314604059
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 685.9737367038068
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
16--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 737.9737367038068
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
1--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 61.6
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 135.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 144.73910524340096
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 154.33910524340095
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 206.33910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 258.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 310.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 362.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 371.93910524340095
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 381.53910524340097
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 433.53910524340097
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 485.53910524340097
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
13--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 559.0782104868019
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
3--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 80.80000000000001
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 102.33910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 175.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 185.47821048680188
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 195.07821048680188
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 204.67821048680187
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 214.27821048680187
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
9--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 266.27821048680187
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 166.2782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 175.8782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 185.47821048680188
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 259.0173157302028
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 311.0173157302028
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 384.5564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 394.1564209736038
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 467.6955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 477.2955262170048
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 486.89552621700483
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 496.49552621700485
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 548.4955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 558.0955262170049
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 610.0955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 683.6346314604059
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 757.1737367038069
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 809.1737367038069
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 861.1737367038069
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 934.7128419472078
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
22--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 1008.2519471906088
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 208.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 260.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 270.2782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 279.87821048680195
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 289.47821048680197
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 299.078210486802
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 372.61731573020296
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 424.61731573020296
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 434.217315730203
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 507.75642097360395
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 517.3564209736039
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 590.8955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 600.4955262170049
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 652.4955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 662.0955262170049
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 671.695526217005
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 681.295526217005
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 733.295526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 806.834631460406
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 816.434631460406
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 826.034631460406
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 878.034631460406
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 930.034631460406
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
26--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 1003.573736703807
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 52.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 61.6
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 71.2
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 80.80000000000001
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 90.4
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 100.0
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 109.6
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 119.19999999999999
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
8--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 192.73910524340096
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 166.2782104868019
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 175.8782104868019
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 249.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 322.9564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 396.4955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 448.4955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 458.0955262170048
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 510.0955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 519.6955262170048
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 571.6955262170048
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 581.2955262170049
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 633.2955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 685.2955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 694.8955262170049
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
17--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 768.4346314604059
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
4--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 90.4
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 61.6
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 113.6
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 165.6
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
4--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 239.13910524340093
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 71.2
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
3--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 144.73910524340096
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 166.2782104868019
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 175.8782104868019
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 185.47821048680188
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 259.0173157302028
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 268.61731573020285
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 342.1564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 351.75642097360384
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 361.35642097360386
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 370.9564209736039
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 380.5564209736039
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
13--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 432.5564209736039
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
4--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 90.4
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 52.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 104.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 113.6
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 123.19999999999999
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 132.79999999999998
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 206.33910524340092
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 279.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 353.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 426.9564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 436.55642097360385
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 446.1564209736039
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 455.7564209736039
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 465.3564209736039
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 474.95642097360394
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 484.55642097360396
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 494.156420973604
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 546.156420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 619.695526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 671.695526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 723.695526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
20--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 797.2346314604059
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 80.80000000000001
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 132.8
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 206.33910524340098
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 279.87821048680195
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 289.47821048680197
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 341.47821048680197
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 415.01731573020294
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 467.01731573020294
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 476.61731573020296
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 486.217315730203
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 495.817315730203
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 547.8173157302031
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 621.356420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 673.356420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 682.956420973604
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 692.5564209736041
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 702.1564209736041
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 711.7564209736041
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 763.7564209736041
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 815.7564209736041
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 867.7564209736041
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 877.3564209736041
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 950.8955262170051
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
26--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 1024.434631460406
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 125.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 177.53910524340097
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 187.13910524340096
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
4--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 239.13910524340096
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 92.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 144.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 154.33910524340095
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 206.33910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 258.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 310.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 319.93910524340095
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 329.53910524340097
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 403.07821048680194
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 455.07821048680194
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
12--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 528.6173157302029
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 57.60000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 67.20000000000002
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 119.20000000000002
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 192.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 202.33910524340095
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 254.33910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 263.93910524340095
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 315.93910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 325.53910524340097
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 335.139105243401
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 408.67821048680196
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 418.278210486802
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 491.81731573020295
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 565.3564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
19--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 638.8955262170049
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 57.60000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 67.20000000000002
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 76.80000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 86.4
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 96.0
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 105.6
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 179.13910524340093
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 231.13910524340093
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 240.73910524340093
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
14--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 314.27821048680187
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
1--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 125.53910524340095
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 52.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 125.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 177.53910524340097
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 229.53910524340097
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 239.13910524340096
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 291.139105243401
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 300.739105243401
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 310.33910524340104
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 319.93910524340106
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 393.478210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 403.07821048680205
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 412.6782104868021
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 464.6782104868021
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 474.2782104868021
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 483.8782104868021
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 535.8782104868021
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 545.4782104868021
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 555.0782104868022
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 564.6782104868022
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 616.6782104868022
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 668.6782104868022
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 678.2782104868022
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 730.2782104868022
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 739.8782104868022
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 813.4173157302032
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 823.0173157302032
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 832.6173157302032
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 842.2173157302033
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
28--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 915.7564209736042
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
1--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 61.6
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 71.2
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 80.80000000000001
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
4--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 154.33910524340098
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 166.2782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 175.8782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
5--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 227.8782104868019
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 61.6
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 71.2
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 80.80000000000001
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 90.4
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 142.4
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 215.93910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 225.53910524340094
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 235.13910524340093
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 244.73910524340093
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 254.33910524340092
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 263.93910524340095
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 337.4782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 347.07821048680194
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 420.6173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 494.1564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 546.1564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 598.1564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
18--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 650.1564209736039
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 52.0
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
1--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 125.53910524340095
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 92.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
3--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 144.73910524340096
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 166.2782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 175.8782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 185.47821048680188
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
6--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 237.47821048680188
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 166.2782104868019
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 239.81731573020284
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 313.3564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 322.9564209736038
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 332.55642097360385
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 342.1564209736039
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 415.69552621700484
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
10--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 467.69552621700484
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 135.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 187.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 196.73910524340096
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 206.33910524340095
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 258.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 310.3391052434009
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 383.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 393.4782104868019
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 403.07821048680194
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 412.67821048680196
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 422.278210486802
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 431.878210486802
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 441.478210486802
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 451.07821048680205
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
16--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 503.07821048680205
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 102.33910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 175.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 227.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 279.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 331.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 383.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 457.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
10--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 509.41731573020286
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 57.60000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 67.20000000000002
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 119.20000000000002
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 171.20000000000002
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 180.8
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 254.33910524340098
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 327.87821048680195
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 337.47821048680197
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 347.078210486802
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 399.078210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 451.078210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 503.078210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 512.678210486802
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
18--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 586.2173157302029
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 111.93910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
5--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 163.93910524340095
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
3--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 80.80000000000001
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
0--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 52.0
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 80.80000000000001
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 154.33910524340098
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 227.87821048680195
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 237.47821048680194
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 247.07821048680194
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 299.07821048680194
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 308.67821048680196
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 318.278210486802
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 327.878210486802
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 337.478210486802
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 347.07821048680205
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 356.6782104868021
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 366.2782104868021
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 439.81731573020306
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 513.356420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 522.956420973604
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 532.5564209736041
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 542.1564209736041
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 594.1564209736041
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 603.7564209736041
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 613.3564209736041
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 665.3564209736041
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 738.8955262170051
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 812.4346314604061
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 822.0346314604061
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 831.6346314604061
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 883.6346314604061
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
30--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 957.1737367038071
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 92.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 166.27821048680192
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 175.87821048680192
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 249.41731573020286
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 322.9564209736038
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 332.55642097360385
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 342.1564209736039
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 351.7564209736039
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 425.29552621700486
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 498.83463146040583
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 550.8346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 602.8346314604058
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 612.4346314604059
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 622.0346314604059
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 631.6346314604059
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 12)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 641.2346314604059
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 650.834631460406
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 702.834631460406
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
20--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 776.3737367038069
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 73.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 125.53910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 199.0782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 251.0782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 303.07821048680194
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 312.67821048680196
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 322.278210486802
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 331.878210486802
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
8--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 405.417315730203
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 156.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 208.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 260.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 312.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 386.21731573020287
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 395.8173157302029
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 405.4173157302029
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 457.4173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 467.01731573020294
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 476.61731573020296
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 486.217315730203
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 495.817315730203
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 569.3564209736039
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 642.8955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 694.8955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 746.8955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 756.4955262170049
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 830.0346314604059
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
20--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 882.0346314604059
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 28.800000000000004
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 38.400000000000006
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 48.00000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 57.60000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 67.20000000000002
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 76.80000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 128.8
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 202.33910524340098
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 254.33910524340098
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 306.339105243401
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 315.939105243401
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 325.539105243401
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 377.539105243401
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 387.13910524340105
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 396.73910524340107
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 406.3391052434011
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 415.9391052434011
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 425.53910524340114
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 435.13910524340116
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 487.13910524340116
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 0)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 496.7391052434012
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 8)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 506.3391052434012
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
24--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.000628539361054709 ++++ 579.8782104868021
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, -4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 19.200000000000003
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 92.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 144.73910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 154.33910524340095
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 206.33910524340095
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 279.8782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 289.4782104868019
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 299.07821048680194
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 308.67821048680196
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 318.278210486802
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 370.278210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 379.878210486802
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 4)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 389.478210486802
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 441.478210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 493.478210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)0
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 503.07821048680205
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 0)1
agent move function == before moving target cell low corner:
(0, 0)
moved============= (0, 0)
moved=============coords: (2.0, 2.0)
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 555.078210486802
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 628.617315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 680.617315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 690.217315730203
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 742.217315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 751.8173157302031
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 12)0
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 761.4173157302031
env step function +++++++++++++State: (2.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 834.956420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 886.956420973604
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 960.495526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 970.095526217005
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1022.095526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1074.095526217005
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1083.695526217005
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1093.2955262170049
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 8)0
agent move function == before moving target cell low corner:
(8, 8)
moved============= (8, 8)
moved=============coords: (10.0, 10.0)
dist to t 0 -- 10.066547885835483
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1145.2955262170049
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,10.0,0) >>> Action: 6 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1218.8346314604057
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1270.8346314604057
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1280.4346314604056
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 1332.4346314604056
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 1342.0346314604055
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1415.5737367038064
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1489.1128419472072
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 1562.651947190608
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 0)1
agent move function == before moving target cell low corner:
(4, 0)
moved============= (4, 0)
moved=============coords: (6.0, 2.0)
dist to t 0 -- 2.2517188546317355
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(8, 4)
bottomLeft: 
(4, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 7.435870295483085, 0.2654930686637851
41--DONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNE
done at other actions totalEner: False, True
Calculating Reward ++++ (50) +++ 0.00044444444444444447 ++++ 1614.651947190608
done??True
False
num covered targets: 2
True
resetting=============
reset drone location: 
(0, 0)
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
cell covered 0
reset target loc: 
(7.435870295483085, 0.2654930686637851)
cell 4, 0: 1
reset target loc: 
(0.8003793425248573, 2.7495488358273916)
cell 0, 0: 1
dist to t 0 -- 5.705891706312759
dist to t 1 -- 1.414536383106243
isTargetInsideCell 0.8003793425248573, 2.7495488358273916
topCOrner: 
(4, 4)
bottomLeft: 
(0, 0)
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY Inside Cell: 0.8003793425248573, 2.7495488358273916
numTargets covered initially:  1
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (-4, 4)1
dist to t 0 -- 5.705891706312759
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 9.600000000000001
env step function +++++++++++++State: (2.0,2.0,1) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 83.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 135.13910524340096
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 8)0
agent move function == before moving target cell low corner:
(4, 8)
moved============= (4, 8)
moved=============coords: (6.0, 10.0)
dist to t 0 -- 9.839834790365309
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 208.6782104868019
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,10.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 282.21731573020287
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 5 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 8)0
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 291.8173157302029
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 1 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 0)0
agent move function == before moving target cell low corner:
(8, 0)
moved============= (8, 0)
moved=============coords: (10.0, 2.0)
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 343.8173157302029
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 353.4173157302029
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 7 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, -4)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 363.01731573020294
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (12, 0)0
dist to t 0 -- 3.0956865856283606
isTargetInsideCell 7.435870295483085, 0.2654930686637851
topCOrner: 
(12, 4)
bottomLeft: 
(8, 0)
not covered -----------------------7.435870295483085, 0.2654930686637851
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 372.61731573020296
env step function +++++++++++++State: (10.0,2.0,0) >>> Action: 0 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (8, 4)0
agent move function == before moving target cell low corner:
(8, 4)
moved============= (8, 4)
moved=============coords: (10.0, 6.0)
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 424.61731573020296
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 6.281666250854871
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 434.217315730203
env step function +++++++++++++State: (10.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 486.217315730203
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 8 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 9.600000000000001 ++++ 495.817315730203
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 2 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 4)0
agent move function == before moving target cell low corner:
(0, 4)
moved============= (0, 4)
moved=============coords: (2.0, 6.0)
dist to t 0 -- 7.901471737268852
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 547.8173157302031
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (2.0,6.0,0) >>> Action: 3 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (4, 4)0
agent move function == before moving target cell low corner:
(4, 4)
moved============= (4, 4)
moved=============coords: (6.0, 6.0)
dist to t 0 -- 5.911538991751113
Calculating Reward ++++ (-1) +++ 0.00044444444444444447 ++++ 599.8173157302031
done??False
False
num covered targets: 1
False
env step function +++++++++++++State: (6.0,6.0,0) >>> Action: 4 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
nextCell: (0, 8)0
agent move function == before moving target cell low corner:
(0, 8)
moved============= (0, 8)
moved=============coords: (2.0, 10.0)
dist to t 0 -- 11.149408552275236
Calculating Reward ++++ (-1) +++ 0.000628539361054709 ++++ 673.356420973604
done??False
False
num covered targets: 1
False
